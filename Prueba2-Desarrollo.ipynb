{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte Práctica\n",
    "\n",
    "Pricila Badilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos desarrollar una máquina capaz de ganar al juego \"Piedra Hoja Tijeras\" anticipando el gesto del adversario.\n",
    "Suponemos que tenemos acceso a datos de sensores EMG (electromigrafía) que miden en tiempo real la actividad muscular del adversario.\n",
    "\n",
    "Tenemos a nuestra disposición un dataset que contiene observaciones de 3 tipos de gestos: piedra (0), hoja (1) y tijeras (2).\n",
    "Por cada observación, tenemos acceso a 8 sensores musculares y se recopila 8 mediciones de cada sensor justo antes de que el jugador revele su gesto. Es decir, tenemos 64 mediciones por cada observación.\n",
    "\n",
    "Descargar [dataset](https://github.com/magister-informatica-uach/INFO268/tree/master/unidad1/prueba2/dataset-prueba2.csv) \n",
    "\n",
    "\n",
    "Queremos aprender un modelo de clasificación capaz de predecir que gesto va a hacer el jugador. \n",
    "\n",
    "1) Desarrollar un script python para entrenar y evaluar al menos 3 modelos de clasificación distintos, limpiando o transformando los datos si lo estiman necesario.\n",
    "\n",
    "2) ¿Qué precisión y recall obtiene?\n",
    "\n",
    "3) ¿Cómo se comparta los puntajas de precisión y recall según el tamaño del dataset de entrenamiento? Probar con varios tamaño de dataset de entrenamiento y graficar las curvas de Precicion o Recall según el tamaño del dataset de entrenamiento. ¿Qué observan? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./dataset-prueba2.csv', names=['S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18',\n",
    "             'S21', 'S22', 'S23', 'S24', 'S25', 'S26', 'S27', 'S28',\n",
    "             'S31', 'S32', 'S33', 'S34', 'S35', 'S36', 'S37', 'S38',\n",
    "             'S41', 'S42', 'S43', 'S44', 'S45', 'S46', 'S47', 'S48',\n",
    "             'S51', 'S52', 'S53', 'S54', 'S55', 'S56', 'S57', 'S58',\n",
    "             'S61', 'S62', 'S63', 'S64', 'S65', 'S66', 'S67', 'S68',\n",
    "             'S71', 'S72', 'S73', 'S74', 'S75', 'S76', 'S77', 'S78',\n",
    "             'S81', 'S82', 'S83', 'S84', 'S85', 'S86', 'S87', 'S88','R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S11</th>\n",
       "      <th>S12</th>\n",
       "      <th>S13</th>\n",
       "      <th>S14</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>S17</th>\n",
       "      <th>S18</th>\n",
       "      <th>S21</th>\n",
       "      <th>S22</th>\n",
       "      <th>...</th>\n",
       "      <th>S78</th>\n",
       "      <th>S81</th>\n",
       "      <th>S82</th>\n",
       "      <th>S83</th>\n",
       "      <th>S84</th>\n",
       "      <th>S85</th>\n",
       "      <th>S86</th>\n",
       "      <th>S87</th>\n",
       "      <th>S88</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    S11  S12  S13  S14   S15   S16    S17   S18   S21  S22 ...   S78   S81  \\\n",
       "0  26.0  4.0  5.0  8.0  -1.0 -13.0 -109.0 -66.0  -9.0  2.0 ... -28.0  61.0   \n",
       "1 -47.0 -6.0 -5.0 -7.0  13.0  -1.0   35.0 -10.0  10.0 -4.0 ... -25.0  47.0   \n",
       "2 -19.0 -8.0 -8.0 -8.0 -21.0  -6.0  -79.0  12.0   0.0  5.0 ... -83.0   7.0   \n",
       "3   2.0  3.0  0.0  2.0   0.0  22.0  106.0 -14.0 -16.0 -2.0 ... -38.0 -11.0   \n",
       "4   6.0  0.0  0.0 -2.0 -14.0  10.0  -51.0   5.0   7.0  0.0 ...  38.0 -35.0   \n",
       "\n",
       "   S82  S83   S84   S85   S86    S87   S88  R  \n",
       "0  4.0  8.0   5.0   4.0  -7.0  -59.0  16.0  0  \n",
       "1  6.0  6.0   5.0  13.0  21.0  111.0  15.0  0  \n",
       "2  7.0  1.0  -8.0   7.0  21.0  114.0  48.0  0  \n",
       "3  4.0  7.0  11.0  33.0  39.0  119.0  43.0  0  \n",
       "4 -8.0  2.0   6.0 -13.0 -24.0 -112.0 -69.0  0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S11    0\n",
       "S12    0\n",
       "S13    0\n",
       "S14    0\n",
       "S15    0\n",
       "S16    0\n",
       "S17    0\n",
       "S18    0\n",
       "S21    0\n",
       "S22    0\n",
       "S23    0\n",
       "S24    0\n",
       "S25    0\n",
       "S26    0\n",
       "S27    0\n",
       "S28    0\n",
       "S31    0\n",
       "S32    0\n",
       "S33    0\n",
       "S34    0\n",
       "S35    0\n",
       "S36    0\n",
       "S37    0\n",
       "S38    0\n",
       "S41    0\n",
       "S42    0\n",
       "S43    0\n",
       "S44    0\n",
       "S45    0\n",
       "S46    0\n",
       "      ..\n",
       "S54    0\n",
       "S55    0\n",
       "S56    0\n",
       "S57    0\n",
       "S58    0\n",
       "S61    0\n",
       "S62    0\n",
       "S63    0\n",
       "S64    0\n",
       "S65    0\n",
       "S66    0\n",
       "S67    0\n",
       "S68    0\n",
       "S71    0\n",
       "S72    0\n",
       "S73    0\n",
       "S74    0\n",
       "S75    0\n",
       "S76    0\n",
       "S77    0\n",
       "S78    0\n",
       "S81    0\n",
       "S82    0\n",
       "S83    0\n",
       "S84    0\n",
       "S85    0\n",
       "S86    0\n",
       "S87    0\n",
       "S88    0\n",
       "R      0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay datos vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8756 entries, 0 to 8755\n",
      "Data columns (total 65 columns):\n",
      "S11    8756 non-null float64\n",
      "S12    8756 non-null float64\n",
      "S13    8756 non-null float64\n",
      "S14    8756 non-null float64\n",
      "S15    8756 non-null float64\n",
      "S16    8756 non-null float64\n",
      "S17    8756 non-null float64\n",
      "S18    8756 non-null float64\n",
      "S21    8756 non-null float64\n",
      "S22    8756 non-null float64\n",
      "S23    8756 non-null float64\n",
      "S24    8756 non-null float64\n",
      "S25    8756 non-null float64\n",
      "S26    8756 non-null float64\n",
      "S27    8756 non-null float64\n",
      "S28    8756 non-null float64\n",
      "S31    8756 non-null float64\n",
      "S32    8756 non-null float64\n",
      "S33    8756 non-null float64\n",
      "S34    8756 non-null float64\n",
      "S35    8756 non-null float64\n",
      "S36    8756 non-null float64\n",
      "S37    8756 non-null float64\n",
      "S38    8756 non-null float64\n",
      "S41    8756 non-null float64\n",
      "S42    8756 non-null float64\n",
      "S43    8756 non-null float64\n",
      "S44    8756 non-null float64\n",
      "S45    8756 non-null float64\n",
      "S46    8756 non-null float64\n",
      "S47    8756 non-null float64\n",
      "S48    8756 non-null float64\n",
      "S51    8756 non-null float64\n",
      "S52    8756 non-null float64\n",
      "S53    8756 non-null float64\n",
      "S54    8756 non-null float64\n",
      "S55    8756 non-null float64\n",
      "S56    8756 non-null float64\n",
      "S57    8756 non-null float64\n",
      "S58    8756 non-null float64\n",
      "S61    8756 non-null float64\n",
      "S62    8756 non-null float64\n",
      "S63    8756 non-null float64\n",
      "S64    8756 non-null float64\n",
      "S65    8756 non-null float64\n",
      "S66    8756 non-null float64\n",
      "S67    8756 non-null float64\n",
      "S68    8756 non-null float64\n",
      "S71    8756 non-null float64\n",
      "S72    8756 non-null float64\n",
      "S73    8756 non-null float64\n",
      "S74    8756 non-null float64\n",
      "S75    8756 non-null float64\n",
      "S76    8756 non-null float64\n",
      "S77    8756 non-null float64\n",
      "S78    8756 non-null float64\n",
      "S81    8756 non-null float64\n",
      "S82    8756 non-null float64\n",
      "S83    8756 non-null float64\n",
      "S84    8756 non-null float64\n",
      "S85    8756 non-null float64\n",
      "S86    8756 non-null float64\n",
      "S87    8756 non-null float64\n",
      "S88    8756 non-null float64\n",
      "R      8756 non-null int64\n",
      "dtypes: float64(64), int64(1)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como con cada sensor se tomaron 8 observaciones, vamos a calcular el promedio para cada sensor muscular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[['S11', 'S21', 'S31', 'S41', 'S51', 'S61', 'S71', 'S81']].mean(axis=1)\n",
    "b = df[['S12', 'S22', 'S32', 'S42', 'S52', 'S62', 'S72', 'S82']].mean(axis=1)\n",
    "c = df[['S13', 'S23', 'S33', 'S43', 'S53', 'S63', 'S73', 'S83']].mean(axis=1)\n",
    "d = df[['S14', 'S24', 'S34', 'S44', 'S54', 'S64', 'S74', 'S84']].mean(axis=1)\n",
    "e = df[['S15', 'S25', 'S35', 'S45', 'S55', 'S65', 'S75', 'S85']].mean(axis=1)\n",
    "f = df[['S16', 'S26', 'S36', 'S46', 'S56', 'S66', 'S76', 'S86']].mean(axis=1)\n",
    "g = df[['S17', 'S27', 'S37', 'S47', 'S57', 'S67', 'S77', 'S87']].mean(axis=1)\n",
    "h = df[['S18', 'S28', 'S38', 'S48', 'S58', 'S68', 'S78', 'S88']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-2.125</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>-48.000</td>\n",
       "      <td>-9.375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.500</td>\n",
       "      <td>4.875</td>\n",
       "      <td>6.375</td>\n",
       "      <td>4.250</td>\n",
       "      <td>-3.750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.250</td>\n",
       "      <td>-1.750</td>\n",
       "      <td>-2.750</td>\n",
       "      <td>-2.875</td>\n",
       "      <td>-1.375</td>\n",
       "      <td>-5.625</td>\n",
       "      <td>-13.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.375</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>3.375</td>\n",
       "      <td>4.500</td>\n",
       "      <td>9.000</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.000</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-2.875</td>\n",
       "      <td>-2.875</td>\n",
       "      <td>-32.125</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5       6      7  R\n",
       "0  8.000  1.500  0.875  0.500 -2.125 -4.750 -48.000 -9.375  0\n",
       "1 -2.875  0.000  1.125  0.500  4.875  6.375   4.250 -3.750  0\n",
       "2 -5.250 -1.750 -2.750 -2.875 -1.375 -5.625 -13.750  0.250  0\n",
       "3 -2.375 -0.625 -0.375 -0.125  3.375  4.500   9.000 -2.500  0\n",
       "4 -6.000 -0.625  0.375  0.500 -2.875 -2.875 -32.125 -7.000  0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([a,b,c,d,e,f,g,h,df[\"R\"]], axis =1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sb.heatmap(df2.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX= df2.iloc[:,:-1]\\ny = df2.iloc[:,len(df2.columns)-1:]\\n'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df.iloc[:,:-1]\n",
    "y = df.iloc[:,len(df.columns)-1:]\n",
    "\n",
    "'''\n",
    "X= df2.iloc[:,:-1]\n",
    "y = df2.iloc[:,len(df2.columns)-1:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estuve entre la duda si usar df2 que cree (con los promedios) o df con todos los datos (sin filtros). Finalmente usé df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S11   S12   S13   S14   S15   S16   S17   S18   S21   S22  ...     S77  \\\n",
      "7997  -4.0 -31.0  10.0  -6.0 -23.0  -1.0  -1.0  -2.0 -23.0 -31.0  ...    -2.0   \n",
      "6781  -6.0  -9.0  -5.0  -5.0 -16.0 -15.0  -9.0 -35.0   3.0  -8.0  ...   -12.0   \n",
      "920   83.0   8.0  -6.0 -13.0  13.0 -41.0 -38.0 -21.0   7.0  12.0  ...    -7.0   \n",
      "2322  18.0  17.0 -11.0  -9.0  -2.0 -37.0 -25.0   8.0 -50.0  25.0  ...    14.0   \n",
      "5569  10.0   2.0  -4.0 -10.0   8.0  15.0  -2.0   0.0  -1.0  -2.0  ...    -3.0   \n",
      "5435  -9.0   1.0   2.0   3.0   4.0 -12.0   1.0   8.0   1.0  -5.0  ...     4.0   \n",
      "2280   3.0  36.0   1.0  -6.0   0.0  63.0  -3.0  23.0  -3.0 -37.0  ...    11.0   \n",
      "1831  -1.0  -2.0   0.0   5.0   3.0  -3.0   6.0  -1.0   3.0   2.0  ...    13.0   \n",
      "2507  13.0  -3.0   1.0  12.0  -4.0  -6.0 -21.0 -25.0 -14.0  -2.0  ...    -9.0   \n",
      "1252   5.0 -27.0   2.0   4.0  12.0  -2.0  18.0   1.0   1.0  18.0  ...    -7.0   \n",
      "4864   4.0  -2.0  -4.0  -1.0  12.0  11.0  -1.0   4.0  -2.0  -3.0  ...    -2.0   \n",
      "6529  18.0  19.0   4.0   0.0  11.0   0.0  -7.0   6.0 -20.0 -43.0  ...     3.0   \n",
      "5062  -8.0   1.0  -2.0  -3.0  28.0  20.0  -1.0 -11.0  15.0  -1.0  ...    -1.0   \n",
      "5903   7.0   8.0   6.0   6.0   0.0   2.0   5.0   9.0   3.0   0.0  ...    -5.0   \n",
      "2029 -14.0  -7.0   1.0  -1.0   5.0   2.0 -14.0   8.0  10.0  24.0  ...    22.0   \n",
      "7185  -7.0  -1.0  -1.0  -7.0 -31.0  -7.0   9.0  -1.0  -1.0  -5.0  ...    -2.0   \n",
      "5175   9.0   2.0   2.0   1.0 -15.0  -9.0   0.0   5.0   4.0   2.0  ...     0.0   \n",
      "554  -15.0  -6.0  -6.0 -14.0 -14.0 -11.0 -27.0 -21.0 -15.0   3.0  ...    10.0   \n",
      "4069  -6.0   1.0  -1.0  -1.0  19.0  16.0  -3.0 -10.0   0.0   1.0  ...     4.0   \n",
      "1548 -25.0  -2.0  -1.0 -11.0  -6.0  -4.0 -87.0  -8.0  50.0  -4.0  ...    30.0   \n",
      "2851 -18.0  -1.0   0.0   5.0   1.0  -1.0  10.0  27.0  11.0   3.0  ...   -28.0   \n",
      "8300  -6.0  18.0  11.0  -3.0  32.0   8.0   3.0 -13.0   0.0 -13.0  ...     5.0   \n",
      "6997  22.0   4.0  -6.0 -12.0 -25.0 -37.0 -17.0  -8.0   5.0  13.0  ...     7.0   \n",
      "6928  14.0   3.0   7.0   6.0   5.0 -32.0   8.0  15.0 -16.0   7.0  ...     1.0   \n",
      "1571 -55.0 -22.0  -4.0   6.0 -37.0 -38.0 -98.0 -38.0  63.0   9.0  ...   -91.0   \n",
      "359  -14.0   7.0   4.0   1.0  -2.0  28.0  -1.0   9.0 -25.0 -10.0  ...  -122.0   \n",
      "7759   7.0  22.0  -3.0   1.0 -13.0  -4.0   8.0  -2.0   5.0  -9.0  ...     8.0   \n",
      "6636   4.0   2.0  -1.0  -2.0 -17.0  11.0   2.0  16.0  19.0   5.0  ...    -2.0   \n",
      "2235 -56.0 -54.0 -26.0   2.0  -9.0   5.0  59.0 -28.0  68.0  -7.0  ...    -8.0   \n",
      "8418   5.0   3.0   3.0  -5.0   5.0  11.0  -4.0   2.0   8.0  11.0  ...     1.0   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...     ...   \n",
      "5692 -20.0  -2.0   0.0   4.0  33.0   1.0   1.0   0.0  16.0  -2.0  ...    -1.0   \n",
      "3363  -1.0  -7.0  -1.0  -4.0  17.0   4.0   1.0  -5.0 -32.0  -7.0  ...     0.0   \n",
      "7720   3.0  -5.0  -5.0 -10.0  -4.0 -35.0  -7.0  -1.0 -17.0   6.0  ...    11.0   \n",
      "7580  -3.0   3.0  -1.0  -1.0 -14.0 -41.0  -6.0   3.0  -7.0  -3.0  ...    -2.0   \n",
      "7630  -1.0  -7.0   0.0  -3.0  -1.0  -3.0   4.0   0.0   3.0  19.0  ...    -4.0   \n",
      "109    4.0   4.0   7.0  14.0  -1.0  -2.0  12.0  30.0  -7.0  -1.0  ...   -52.0   \n",
      "3998  -5.0  -2.0  -2.0   0.0   8.0  10.0  -2.0  -4.0   9.0   1.0  ...     1.0   \n",
      "6408 -23.0  24.0   3.0   3.0 -16.0   6.0   1.0   0.0   4.0  61.0  ...     6.0   \n",
      "1842   0.0   0.0  -2.0   6.0   3.0  -5.0  -9.0   3.0  -1.0   2.0  ...    24.0   \n",
      "2991  -7.0   2.0   0.0  -1.0  11.0   0.0  -3.0 -20.0   6.0  -2.0  ...     2.0   \n",
      "4166   1.0   9.0   2.0   2.0  -8.0 -10.0   0.0  15.0  27.0   0.0  ...     5.0   \n",
      "3377  24.0   4.0  -1.0  -2.0   6.0 -19.0   2.0  -6.0 -14.0  -4.0  ...     2.0   \n",
      "5180 -10.0   0.0  -1.0  -3.0   5.0   6.0  -2.0 -10.0  -6.0  -2.0  ...    -2.0   \n",
      "8061   4.0   9.0   3.0   0.0  -4.0   6.0   6.0  20.0   1.0   3.0  ...    -1.0   \n",
      "4119 -19.0  -3.0  -3.0  -1.0   3.0  18.0   0.0 -12.0 -12.0  -2.0  ...    -5.0   \n",
      "2191 -20.0  -4.0  -2.0   1.0   9.0  13.0  -3.0  62.0  35.0  38.0  ...   -37.0   \n",
      "5852 -13.0  33.0 -17.0 -14.0 -11.0 -27.0 -14.0 -48.0  20.0 -24.0  ...    15.0   \n",
      "4553  -7.0   1.0  -2.0  -2.0  14.0  13.0  -1.0  -9.0  -8.0  -3.0  ...    -2.0   \n",
      "8152 -26.0 -72.0  -9.0  -8.0  28.0  49.0   1.0 -14.0  -1.0  -2.0  ...    -1.0   \n",
      "6020  -7.0  -4.0  -6.0  -3.0  10.0  -2.0  -5.0  -2.0   2.0   0.0  ...     0.0   \n",
      "4647  17.0   1.0   1.0   0.0 -29.0 -36.0  -4.0   9.0 -12.0  -3.0  ...    -1.0   \n",
      "4616   8.0  -1.0  -1.0  -6.0  -1.0  -3.0  -2.0  -5.0 -22.0  -8.0  ...     2.0   \n",
      "7382  -4.0  28.0  -4.0  -1.0 -13.0  -3.0  -1.0  10.0  15.0   0.0  ...    -2.0   \n",
      "6118   2.0  -6.0  -1.0  -3.0   7.0 -24.0  -2.0 -11.0   0.0 -33.0  ...     2.0   \n",
      "5494  54.0   5.0   2.0   2.0 -31.0 -27.0  -4.0   1.0  14.0  -2.0  ...    -2.0   \n",
      "2491  -7.0  -3.0   4.0   7.0 -12.0   6.0  -7.0   0.0 -13.0 -22.0  ...   -35.0   \n",
      "6431  -1.0  12.0   3.0  -4.0 -12.0 -15.0 -24.0 -15.0   9.0  -5.0  ...     3.0   \n",
      "2174   9.0   6.0  -2.0  15.0 -11.0 -26.0 -58.0 -10.0 -16.0 -18.0  ...    -3.0   \n",
      "8040 -14.0  -7.0   1.0  -7.0   3.0  15.0   1.0  -1.0  14.0  34.0  ...    -4.0   \n",
      "6638   6.0  18.0   2.0  13.0  34.0  44.0  22.0 -32.0  15.0  -1.0  ...     5.0   \n",
      "\n",
      "       S78   S81   S82  S83   S84   S85   S86    S87   S88  \n",
      "7997  -4.0   5.0   9.0  4.0   2.0 -14.0  -4.0    2.0  -6.0  \n",
      "6781  -9.0  21.0  52.0 -3.0  -3.0 -25.0 -26.0   -5.0  28.0  \n",
      "920   -8.0   6.0  -3.0 -2.0   7.0  -7.0  -3.0   -7.0  -9.0  \n",
      "2322 -13.0   6.0  51.0  7.0 -15.0 -20.0   8.0  -57.0   1.0  \n",
      "5569   1.0 -10.0  -3.0  0.0   9.0 -10.0  28.0    1.0  -7.0  \n",
      "5435   7.0 -25.0  -3.0 -1.0  -4.0  -3.0  15.0    1.0   9.0  \n",
      "2280   7.0  -4.0  -1.0 -5.0  -2.0  20.0   2.0  -29.0  -2.0  \n",
      "1831   5.0   1.0   1.0  1.0  -3.0  19.0  -2.0    5.0   4.0  \n",
      "2507  24.0  64.0   1.0  2.0 -15.0  -5.0   5.0    4.0  15.0  \n",
      "1252 -17.0  18.0  18.0  6.0   5.0  -7.0  -7.0 -103.0  10.0  \n",
      "4864  -1.0   7.0   1.0  2.0   2.0  -8.0   7.0    0.0   0.0  \n",
      "6529  -7.0  21.0   7.0 -1.0  -2.0 -28.0  45.0    3.0  15.0  \n",
      "5062   0.0 -23.0  -1.0 -1.0  -4.0  16.0  -1.0    1.0  -5.0  \n",
      "5903  17.0  -8.0  -1.0 -4.0 -10.0  -2.0 -18.0   -4.0  -9.0  \n",
      "2029  -3.0  -9.0 -25.0 -5.0   3.0  11.0  18.0  -42.0 -17.0  \n",
      "7185  -3.0  26.0  22.0  9.0  10.0  -6.0  -6.0   14.0  11.0  \n",
      "5175  -3.0  -2.0  -2.0 -2.0  -4.0 -12.0  13.0   -1.0  -4.0  \n",
      "554    3.0  -5.0   0.0 -2.0  -9.0  14.0   2.0   -7.0 -17.0  \n",
      "4069   5.0  12.0   3.0  0.0   2.0  26.0 -15.0    0.0  -7.0  \n",
      "1548  -3.0   2.0  -5.0 -6.0  -9.0  -7.0   3.0   -2.0  34.0  \n",
      "2851  -3.0  -4.0  -3.0 -4.0  -7.0   0.0  -7.0  -19.0  34.0  \n",
      "8300   0.0 -11.0 -15.0 -4.0  -1.0 -15.0 -65.0   -5.0 -15.0  \n",
      "6997  18.0  17.0  35.0  2.0  20.0  36.0 -21.0  -15.0 -46.0  \n",
      "6928  -5.0  59.0  12.0 -6.0  -5.0 -24.0 -25.0   11.0  -5.0  \n",
      "1571 -80.0  49.0   2.0  0.0  12.0   1.0  -2.0   70.0  60.0  \n",
      "359  -52.0 -70.0 -27.0 -7.0  38.0  -3.0 -43.0    1.0 -26.0  \n",
      "7759   1.0  21.0   1.0  2.0   1.0   3.0 -25.0  -10.0 -13.0  \n",
      "6636  66.0  24.0  13.0 -1.0   0.0  -1.0  -6.0  -20.0 -34.0  \n",
      "2235 -11.0  24.0   3.0 -2.0  -5.0  -5.0   5.0    2.0   5.0  \n",
      "8418   0.0  17.0  17.0 -7.0  -7.0 -31.0 -91.0   -4.0  18.0  \n",
      "...    ...   ...   ...  ...   ...   ...   ...    ...   ...  \n",
      "5692   0.0 -10.0  -1.0 -1.0   0.0  29.0   1.0   -3.0  -9.0  \n",
      "3363  -2.0 -15.0  -5.0 -4.0  -6.0  15.0  21.0   -2.0  -4.0  \n",
      "7720 -11.0  -3.0   1.0  3.0   0.0 -29.0 -30.0   -5.0   2.0  \n",
      "7580   3.0  -5.0  -3.0  2.0   0.0  12.0   3.0   12.0  -7.0  \n",
      "7630   6.0  -1.0   5.0 -7.0  -8.0   1.0 -25.0   -6.0 -21.0  \n",
      "109  -34.0   7.0   3.0  1.0   2.0  17.0  17.0   76.0   8.0  \n",
      "3998  18.0  36.0   8.0  2.0   2.0 -57.0 -71.0    0.0  22.0  \n",
      "6408   6.0  15.0   3.0  9.0  -1.0  13.0  74.0    3.0 -30.0  \n",
      "1842  10.0  -1.0 -12.0 -3.0  -3.0   3.0   1.0   -1.0   4.0  \n",
      "2991  -2.0 -15.0  -5.0 -4.0  -6.0  29.0  57.0    0.0   4.0  \n",
      "4166 -13.0  10.0   1.0  3.0   3.0   8.0 -11.0   -3.0   1.0  \n",
      "3377   3.0   0.0   2.0  1.0   0.0   5.0  -6.0    2.0  -2.0  \n",
      "5180  -1.0   2.0  -2.0 -5.0  -3.0   8.0   5.0   -1.0  -4.0  \n",
      "8061 -18.0  42.0  12.0 -3.0  -1.0  19.0  12.0    0.0  -5.0  \n",
      "4119   4.0  -9.0  -4.0 -3.0  -2.0  15.0  11.0   -6.0  -7.0  \n",
      "2191  -7.0   9.0  28.0 -5.0  37.0  12.0 -12.0  -10.0  34.0  \n",
      "5852  -1.0 -21.0   2.0 -1.0  -4.0  -8.0   6.0   -7.0  -9.0  \n",
      "4553  -4.0 -28.0  -1.0  0.0   5.0 -13.0 -13.0   -3.0  -7.0  \n",
      "8152  -1.0  -3.0 -15.0 -2.0   0.0 -15.0  -4.0    0.0   2.0  \n",
      "6020   3.0   3.0   6.0  2.0  -1.0 -34.0  -2.0   -4.0   2.0  \n",
      "4647   2.0  13.0   2.0 -1.0   0.0   6.0  11.0    4.0  15.0  \n",
      "4616  -4.0 -22.0  -6.0 -4.0  -9.0  15.0  27.0   -3.0  -6.0  \n",
      "7382   9.0  -3.0 -28.0  0.0   1.0   4.0  28.0   -1.0   9.0  \n",
      "6118  13.0  36.0  15.0 -1.0  -3.0  -8.0   2.0   -5.0 -23.0  \n",
      "5494  -1.0  12.0  -1.0 -4.0  -7.0  28.0  21.0    3.0   1.0  \n",
      "2491 -10.0  -4.0  -5.0 -8.0 -18.0  -5.0  12.0   10.0   6.0  \n",
      "6431   7.0 -27.0 -36.0  2.0   7.0   5.0   8.0    6.0 -24.0  \n",
      "2174  15.0 -23.0 -19.0 -8.0 -15.0   7.0  25.0  -26.0 -18.0  \n",
      "8040   1.0 -24.0 -20.0 -4.0  -5.0  -3.0 -22.0    1.0  11.0  \n",
      "6638  -9.0  15.0 -11.0  2.0   9.0  -2.0 -62.0    1.0   9.0  \n",
      "\n",
      "[2627 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=25)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Árbol de Decision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "#entrenamiento\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[782  15  93]\n",
      " [ 10 751  87]\n",
      " [ 63  94 732]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       890\n",
      "           1       0.87      0.89      0.88       848\n",
      "           2       0.80      0.82      0.81       889\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2627\n",
      "   macro avg       0.86      0.86      0.86      2627\n",
      "weighted avg       0.86      0.86      0.86      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Print de la matriz de confusión'''\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresión Logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficientes del modelo: [[-3.39817617e-04  1.17208510e-03 -3.43428425e-05 -2.01776581e-03\n",
      "   1.11405350e-03  2.09951600e-03 -9.52807311e-03  6.00188596e-03\n",
      "  -9.79923382e-04  5.38488902e-04  1.30055612e-03 -3.28866716e-03\n",
      "   1.00106025e-03  3.86095069e-03 -1.44331346e-02  8.20349753e-03\n",
      "  -2.17813264e-03  1.88457398e-03 -2.50264168e-04 -4.83438567e-03\n",
      "   5.48188972e-04  5.05994800e-03 -1.61244976e-02  6.39103917e-03\n",
      "  -1.50217868e-03  4.92117197e-04 -1.01051402e-03 -4.29224259e-03\n",
      "   2.89024709e-03  4.47113038e-03 -2.04239816e-02  9.53936898e-03\n",
      "  -2.87574230e-03 -1.81167373e-05  2.83836979e-03 -8.32761088e-03\n",
      "   2.50423863e-03  2.58516237e-03 -2.34517521e-02  1.33112483e-02\n",
      "  -2.41399850e-03  2.26852997e-03  6.42261607e-03 -7.88429014e-03\n",
      "   5.14596101e-03  2.47450680e-03 -1.99534320e-02  8.54850268e-03\n",
      "  -2.72543425e-03 -1.08609321e-03  6.65368077e-03 -1.26823082e-02\n",
      "   3.25290203e-03  2.14288770e-03 -1.54223338e-02  7.77921834e-03\n",
      "  -1.22043307e-03  6.86091327e-05  6.69875833e-04 -5.06741328e-03\n",
      "   1.81863007e-03  5.23825556e-04 -1.07638117e-02  4.58578735e-03]\n",
      " [ 2.56728260e-03 -1.17381948e-03  4.74940074e-04 -7.75118427e-04\n",
      "  -2.87318638e-03  1.42472304e-04  5.35129410e-03 -4.08206610e-03\n",
      "   1.22515801e-03 -1.04765218e-03 -7.50672480e-03  2.05010958e-03\n",
      "  -2.67154739e-03 -1.20046925e-03  7.55277411e-03 -3.62076376e-03\n",
      "  -2.40300484e-04 -2.55310637e-03  1.62293019e-03  2.95455472e-03\n",
      "  -1.41506383e-03 -2.87010820e-03  8.97603145e-03 -2.96506612e-03\n",
      "  -5.80845274e-04 -1.61245290e-03  1.13480520e-02 -5.41176158e-04\n",
      "   4.58771192e-06 -3.16127463e-03  1.05753683e-02 -2.91334479e-03\n",
      "  -3.49616394e-03 -2.53407948e-04  2.74958916e-03  1.68715901e-03\n",
      "   1.09164953e-04 -9.90041819e-04  1.23205114e-02 -5.53134558e-03\n",
      "  -1.21151405e-03  3.63707650e-04  5.46815045e-03  4.89681194e-03\n",
      "  -6.73771436e-05 -2.32132053e-03  1.09259378e-02 -5.17806477e-03\n",
      "  -1.26504031e-03  4.41092119e-04  1.43927539e-03  9.81781610e-03\n",
      "  -7.65738623e-06 -4.30442987e-04  8.15914477e-03 -2.34424837e-03\n",
      "  -1.95848099e-03  1.40576136e-03 -5.19985319e-03  5.85284476e-03\n",
      "   1.80343174e-03 -1.98051278e-04  6.48320188e-03 -2.96615949e-03]\n",
      " [-2.27084035e-03  7.65885871e-06 -6.49700134e-04  2.65215678e-03\n",
      "   1.85397591e-03 -2.40356723e-03  5.28202722e-03 -2.29010589e-03\n",
      "  -2.88449082e-04  3.47843310e-04  6.03006214e-03  8.88465940e-04\n",
      "   1.64377739e-03 -2.90200791e-03  8.49274519e-03 -4.61640535e-03\n",
      "   2.28528051e-03  5.72167879e-04 -8.48017222e-04  6.02944916e-04\n",
      "   9.71201655e-04 -2.48624281e-03  9.11975964e-03 -3.89411741e-03\n",
      "   1.94129573e-03  1.03557139e-03 -1.07170448e-02  4.62697823e-03\n",
      "  -2.71704513e-03 -1.70045336e-03  1.17830739e-02 -7.35438858e-03\n",
      "   6.09132381e-03  2.58014718e-04 -5.21840821e-03  6.30383078e-03\n",
      "  -2.53715931e-03 -1.97738678e-03  1.28869861e-02 -8.44527737e-03\n",
      "   3.60961311e-03 -2.62519482e-03 -1.17216505e-02  3.24442892e-03\n",
      "  -4.69653037e-03 -4.24128631e-04  1.05680433e-02 -3.29432364e-03\n",
      "   3.77070727e-03  6.56960403e-04 -7.58602939e-03  2.46451362e-03\n",
      "  -3.01968913e-03 -1.90681874e-03  8.49551879e-03 -5.58652579e-03\n",
      "   3.10141018e-03 -1.41320124e-03  4.62784790e-03 -8.08871468e-04\n",
      "  -3.41008206e-03 -6.07493382e-04  5.47712753e-03 -1.92157041e-03]]\n",
      "intercept: [-0.91655077 -0.59832497 -0.62195051]\n"
     ]
    }
   ],
   "source": [
    "print(\"coeficientes del modelo: \"+str(LogReg.coef_))\n",
    "print(\"intercept: \"+str(LogReg.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.45      0.51       890\n",
      "           1       0.39      0.44      0.41       848\n",
      "           2       0.38      0.42      0.40       889\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      2627\n",
      "   macro avg       0.45      0.44      0.44      2627\n",
      "weighted avg       0.45      0.44      0.44      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[871   3  16]\n",
      " [  2 798  48]\n",
      " [ 46  22 821]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       890\n",
      "           1       0.97      0.94      0.96       848\n",
      "           2       0.93      0.92      0.93       889\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2627\n",
      "   macro avg       0.95      0.95      0.95      2627\n",
      "weighted avg       0.95      0.95      0.95      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor precisión y recall se obtuvo con el modelo de Random Forest y Árbol de Decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) ¿Cómo se comparta los puntajas de precisión y recall según el tamaño del dataset de entrenamiento? Probar con varios tamaño de dataset de entrenamiento y graficar las curvas de Precicion o Recall según el tamaño del dataset de entrenamiento. ¿Qué observan?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset entrenamiento pequeño**\n",
    "\n",
    "2626*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S11   S12   S13   S14   S15    S16   S17   S18   S21   S22  ...    S77  \\\n",
      "1735   0.0  10.0   5.0  21.0   2.0   -8.0  15.0  19.0 -12.0 -15.0  ...   -9.0   \n",
      "2387 -12.0 -15.0  -8.0  -7.0   3.0  -22.0   6.0   7.0  -7.0  16.0  ...   42.0   \n",
      "74    10.0   0.0   0.0   3.0   6.0   19.0  54.0  27.0  12.0  -2.0  ...   23.0   \n",
      "621  -22.0  -4.0  -1.0   1.0  -5.0  -15.0 -22.0  40.0  32.0   3.0  ...  -12.0   \n",
      "8370  -1.0   1.0  -2.0   3.0  -5.0  -12.0  -3.0 -24.0 -24.0  -3.0  ...   -1.0   \n",
      "587  -10.0  -2.0  -1.0  10.0   8.0   -6.0  34.0  23.0 -19.0   1.0  ...    3.0   \n",
      "7190  -3.0 -16.0  -9.0  -8.0   3.0   33.0  -2.0  -8.0 -14.0  35.0  ...   -3.0   \n",
      "8025  10.0 -34.0 -11.0  -5.0  -5.0   26.0  -1.0   6.0 -16.0   4.0  ...   -3.0   \n",
      "379   29.0  11.0   6.0   4.0   9.0   24.0 -12.0  39.0 -26.0 -12.0  ...  -18.0   \n",
      "4257   9.0   3.0   2.0   4.0   4.0    1.0   1.0  -1.0  -8.0  -5.0  ...    3.0   \n",
      "8529  66.0  17.0  -5.0   0.0  23.0   20.0  -3.0   0.0  -4.0   1.0  ...   -2.0   \n",
      "3981   2.0   1.0   3.0   5.0   1.0    6.0   0.0  -6.0  -8.0  -1.0  ...   -1.0   \n",
      "6035 -12.0  17.0   8.0   6.0  22.0   29.0  -1.0 -11.0 -25.0   1.0  ...    1.0   \n",
      "545   31.0   2.0   1.0  11.0 -12.0  -16.0 -30.0 -15.0 -18.0  -6.0  ...   -1.0   \n",
      "6670   9.0  21.0   7.0   1.0 -36.0  -48.0 -16.0 -17.0 -16.0 -18.0  ...  -17.0   \n",
      "7618   3.0  -4.0 -10.0   2.0  -1.0   12.0 -11.0 -24.0  -7.0 -22.0  ...   -2.0   \n",
      "1918  -1.0   6.0  -6.0   9.0  30.0    7.0 -20.0   8.0  -9.0 -16.0  ...  -84.0   \n",
      "1050  18.0  19.0   1.0  -7.0   1.0  -22.0  -3.0  -7.0 -18.0 -25.0  ...   -8.0   \n",
      "7253 -17.0 -13.0  -2.0  -3.0   2.0   -6.0 -18.0 -17.0 -14.0 -17.0  ...    1.0   \n",
      "7224  -1.0  26.0  -7.0  -2.0 -34.0  -41.0  -1.0  11.0  22.0   0.0  ...   11.0   \n",
      "8407   4.0  32.0   0.0  -1.0 -24.0  -31.0  -5.0  -6.0  -6.0 -18.0  ...    2.0   \n",
      "6845 -20.0  -6.0   9.0   6.0  -4.0    6.0   9.0 -12.0 -15.0 -28.0  ...   -2.0   \n",
      "5937   5.0   9.0  -5.0  -7.0 -18.0  -48.0  -7.0  -2.0  -4.0   9.0  ...   -4.0   \n",
      "5869  -5.0  17.0  15.0  11.0  12.0   29.0  -7.0 -38.0  15.0  13.0  ...    1.0   \n",
      "2803   5.0  -3.0  -7.0 -13.0  -5.0   14.0  17.0   6.0 -11.0  -1.0  ...  -14.0   \n",
      "7166  12.0   8.0   1.0  -5.0 -36.0  -35.0  -5.0   4.0  -2.0  10.0  ...  -13.0   \n",
      "8591  -5.0   4.0  -7.0  -6.0  21.0   -5.0  -5.0  -9.0   6.0   0.0  ...    3.0   \n",
      "3863   4.0  -3.0  -5.0  -6.0  17.0   27.0  -6.0  -7.0 -12.0   0.0  ...    0.0   \n",
      "5724 -11.0  -1.0  -1.0  -3.0 -19.0   -7.0  -4.0   0.0  22.0   6.0  ...   -2.0   \n",
      "1114  -4.0   3.0  -3.0  -6.0  -6.0   -6.0 -36.0  -8.0  -4.0   9.0  ...   -8.0   \n",
      "...    ...   ...   ...   ...   ...    ...   ...   ...   ...   ...  ...    ...   \n",
      "5534 -17.0  -6.0  -2.0  -8.0 -23.0   -6.0  -5.0  -4.0  -6.0   2.0  ...   -1.0   \n",
      "7570  13.0   2.0 -16.0  -5.0   5.0   -4.0   1.0   2.0   3.0  33.0  ...    4.0   \n",
      "1755  -6.0 -31.0 -21.0  -9.0   6.0  -18.0   3.0 -13.0  -2.0  -1.0  ...   -6.0   \n",
      "5889 -22.0 -12.0  11.0  13.0  25.0  127.0  33.0  -8.0 -12.0  -3.0  ...  -11.0   \n",
      "6972 -30.0 -13.0   2.0   7.0   9.0   39.0  -1.0   0.0  -9.0 -14.0  ...  -24.0   \n",
      "3232  -3.0   0.0   0.0   4.0  17.0    8.0   2.0   3.0   1.0  -6.0  ...    0.0   \n",
      "2697  16.0  -6.0  -6.0  -5.0  -5.0    1.0 -32.0 -30.0  -8.0   0.0  ...   25.0   \n",
      "4658 -23.0  -3.0   1.0  -2.0 -17.0   15.0  -3.0  -8.0 -12.0  -2.0  ...   -4.0   \n",
      "2157   0.0  10.0  17.0   3.0  13.0  -11.0   8.0   5.0   2.0   2.0  ...   15.0   \n",
      "7824  -8.0 -16.0  -3.0  -4.0  22.0   20.0   7.0  17.0 -13.0  -6.0  ...  -11.0   \n",
      "5679  -8.0  -3.0  -1.0  -1.0  26.0    6.0   0.0  -8.0   3.0   1.0  ...    1.0   \n",
      "4400 -23.0  -4.0  -1.0   1.0   2.0   -4.0   2.0 -20.0   0.0   1.0  ...   -4.0   \n",
      "5023 -10.0  -8.0  -5.0  -6.0 -16.0   37.0  -1.0  -5.0  -9.0   2.0  ...   -3.0   \n",
      "6550 -49.0  12.0   7.0  11.0  14.0   18.0   8.0  -6.0 -11.0 -15.0  ...  -11.0   \n",
      "6913  28.0 -15.0  -1.0  13.0  -5.0   24.0  -8.0   3.0  19.0   5.0  ...  -17.0   \n",
      "7427 -37.0  13.0 -17.0 -10.0 -26.0  -13.0 -10.0 -12.0   8.0  13.0  ...   -4.0   \n",
      "6785 -20.0  28.0   8.0  -4.0  22.0   -9.0  -2.0 -21.0  14.0  24.0  ...   17.0   \n",
      "8692   7.0  -4.0  -7.0  -7.0 -19.0  -25.0  -4.0  -8.0  -7.0 -15.0  ...   -3.0   \n",
      "2975  -6.0  -3.0  -6.0  -7.0 -20.0   18.0   0.0  -4.0   1.0   2.0  ...   -4.0   \n",
      "3325 -18.0  -2.0  -1.0   1.0  -9.0   13.0   0.0  -2.0  -8.0  -3.0  ...   -2.0   \n",
      "1881  -8.0  -3.0  -1.0 -21.0  -3.0   -6.0 -23.0 -22.0  10.0  18.0  ...    0.0   \n",
      "7324   3.0  19.0   1.0   5.0  36.0   13.0   3.0  -9.0  -6.0 -13.0  ...    3.0   \n",
      "1160  19.0 -21.0  -5.0   3.0   1.0  -19.0 -19.0  -4.0 -43.0  13.0  ...  -68.0   \n",
      "4861 -27.0  -3.0   1.0   4.0   4.0  -10.0   1.0   3.0   8.0   1.0  ...   -2.0   \n",
      "7084 -15.0   3.0  -9.0  -5.0  -7.0   -4.0 -14.0 -11.0  13.0  -6.0  ...   -6.0   \n",
      "1175  -4.0  -1.0  -6.0 -11.0 -15.0   -8.0  -8.0 -67.0  -8.0   4.0  ...   27.0   \n",
      "8447  -6.0  -8.0  -6.0  -6.0 -24.0   -6.0   4.0  20.0  -9.0  -9.0  ...   -2.0   \n",
      "2934  12.0  -5.0   0.0   1.0  -5.0  -31.0  -4.0   6.0   7.0   3.0  ...    1.0   \n",
      "6618  15.0  18.0   2.0  -2.0   2.0   34.0   4.0 -15.0 -28.0 -35.0  ...    1.0   \n",
      "8510  32.0   9.0   1.0   1.0 -15.0   25.0   8.0  16.0   9.0 -11.0  ...   -6.0   \n",
      "\n",
      "       S78   S81   S82   S83   S84   S85   S86    S87   S88  \n",
      "1735  -1.0 -27.0   5.0   1.0   2.0   5.0  -8.0  -22.0   7.0  \n",
      "2387 -26.0 -17.0 -10.0  -1.0   2.0  10.0  24.0   56.0   6.0  \n",
      "74    46.0 -14.0  -1.0   2.0   6.0   0.0  13.0   11.0  46.0  \n",
      "621   12.0 -14.0  -6.0  -6.0  15.0  -3.0 -12.0 -123.0 -31.0  \n",
      "8370 -10.0  -7.0  19.0  11.0  -5.0  25.0 -24.0   -1.0   8.0  \n",
      "587    2.0   4.0  -1.0  -1.0  -2.0  -3.0  -6.0  -31.0   1.0  \n",
      "7190  13.0   3.0  -2.0   3.0  10.0  -4.0 -29.0   -4.0   0.0  \n",
      "8025 -13.0   0.0  -5.0  -2.0   8.0 -29.0   7.0    1.0  18.0  \n",
      "379  -43.0  -8.0  -1.0   8.0   8.0 -29.0 -37.0   70.0  21.0  \n",
      "4257  17.0 -11.0   3.0   2.0   3.0  34.0   0.0   -7.0 -23.0  \n",
      "8529 -11.0  98.0  23.0  -5.0   1.0 -26.0  -9.0   -1.0  13.0  \n",
      "3981  16.0 -10.0  -1.0  -7.0  -3.0 -10.0  -8.0    0.0  -8.0  \n",
      "6035   6.0   7.0   7.0   3.0   2.0  -1.0   7.0    2.0 -17.0  \n",
      "545  -18.0 -19.0  -3.0   2.0   2.0 -20.0 -16.0   34.0  -9.0  \n",
      "6670  10.0  -7.0  -2.0   1.0  -3.0 -31.0 -28.0    9.0 -11.0  \n",
      "7618 -33.0  11.0   1.0   3.0  -5.0 -11.0 -28.0    2.0  13.0  \n",
      "1918 -22.0   0.0   5.0  -1.0   1.0  36.0 -10.0   78.0  18.0  \n",
      "1050   6.0 -18.0   5.0  -6.0   5.0   8.0 -21.0    7.0 -15.0  \n",
      "7253 -11.0  -2.0   2.0   1.0  -1.0  22.0  -2.0  -15.0   7.0  \n",
      "7224   0.0   9.0   4.0   3.0   9.0  46.0   8.0    9.0   5.0  \n",
      "8407 -17.0   3.0   4.0   6.0   2.0 -35.0 -58.0   -7.0   9.0  \n",
      "6845  -8.0  26.0  12.0   0.0   2.0  -4.0  -1.0   -1.0  -2.0  \n",
      "5937 -10.0  -2.0  -2.0   2.0   0.0  -1.0  11.0    2.0  -7.0  \n",
      "5869   1.0   1.0 -42.0 -13.0 -13.0   9.0   6.0   -9.0  -7.0  \n",
      "2803   9.0  -2.0  -4.0  -1.0 -13.0  -7.0   0.0   10.0 -14.0  \n",
      "7166  -9.0  -5.0  -8.0  -5.0  -9.0   0.0 -19.0  -11.0   1.0  \n",
      "8591   3.0   1.0  -9.0  -9.0   7.0   5.0 -29.0   -4.0  -3.0  \n",
      "3863  -4.0 -23.0  -2.0  -3.0  -2.0  26.0  14.0   -3.0  -3.0  \n",
      "5724  -6.0 -10.0  -2.0  -2.0   0.0  21.0  11.0    1.0  -1.0  \n",
      "1114  -8.0  -6.0  -2.0   7.0   3.0   4.0   4.0   35.0   2.0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...    ...   ...  \n",
      "5534   0.0   6.0   2.0  -1.0   4.0  25.0  11.0    0.0  -6.0  \n",
      "7570 -14.0 -14.0   4.0  -7.0  -9.0 -31.0 -39.0   -6.0 -12.0  \n",
      "1755 -11.0  10.0   3.0  -5.0 -18.0  -4.0  -9.0   -6.0   2.0  \n",
      "5889 -24.0   1.0   0.0   4.0   2.0   7.0  -5.0    4.0  -5.0  \n",
      "6972 -16.0 -26.0  -2.0 -10.0 -10.0   7.0   9.0    6.0  12.0  \n",
      "3232  -2.0   2.0  -1.0  -3.0  -7.0  -2.0  22.0    1.0  -1.0  \n",
      "2697 -57.0   9.0   1.0  -1.0  -2.0   8.0   5.0   20.0  34.0  \n",
      "4658  -4.0   4.0   0.0  -5.0  -8.0  14.0  20.0   -1.0   2.0  \n",
      "2157  19.0   2.0 -10.0   1.0   0.0  -3.0   7.0   20.0  -3.0  \n",
      "7824   1.0  -3.0  12.0   3.0   6.0   6.0  26.0    8.0  17.0  \n",
      "5679   5.0  -4.0  -3.0  -3.0  -6.0 -23.0   3.0   -3.0  -4.0  \n",
      "4400  -9.0  -4.0  -3.0   1.0   0.0   0.0 -11.0   -4.0  -5.0  \n",
      "5023  -9.0  -8.0  -2.0  -3.0  -6.0   7.0  14.0    2.0   0.0  \n",
      "6550   5.0   6.0 -10.0  -5.0   1.0   7.0  56.0    8.0 -21.0  \n",
      "6913  27.0  -9.0 -24.0  -7.0  -5.0  -2.0 -10.0    5.0 -19.0  \n",
      "7427   1.0  -6.0  13.0   1.0   3.0  16.0   2.0    7.0   5.0  \n",
      "6785   6.0  12.0  -5.0  -8.0  -2.0   2.0 -28.0  -11.0 -12.0  \n",
      "8692   6.0   2.0  37.0   4.0  -1.0  -7.0  33.0    2.0   9.0  \n",
      "2975   5.0   7.0  -2.0   1.0  -1.0 -34.0 -33.0   -8.0  -6.0  \n",
      "3325  -6.0   0.0   0.0  -1.0  -1.0  11.0  -5.0    1.0   0.0  \n",
      "1881 -15.0  -5.0 -12.0  -2.0  -3.0   2.0   4.0  -24.0   4.0  \n",
      "7324  16.0   6.0  12.0  11.0  22.0   8.0  -5.0    2.0  -4.0  \n",
      "1160  -3.0  17.0 -21.0  -2.0   2.0  -9.0 -32.0 -104.0  -8.0  \n",
      "4861  -1.0   4.0   1.0  -1.0  -4.0  16.0  10.0    1.0  -2.0  \n",
      "7084   7.0 -34.0  -2.0   1.0   3.0   8.0  38.0   -9.0 -23.0  \n",
      "1175 -23.0 -96.0 -10.0  -5.0   1.0 -22.0 -42.0  -87.0 -41.0  \n",
      "8447 -13.0  21.0  40.0  12.0  -3.0 -10.0 -41.0  -11.0   1.0  \n",
      "2934   4.0  -8.0   2.0  -2.0  -3.0  12.0  17.0    0.0   2.0  \n",
      "6618   7.0 -29.0 -19.0  -4.0  -7.0 -16.0 -41.0   -9.0 -32.0  \n",
      "8510   1.0   2.0   7.0  -5.0  -8.0  -7.0  22.0    0.0 -12.0  \n",
      "\n",
      "[2626 rows x 64 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.3, random_state=25)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1802   26  234]\n",
      " [  19 1744  265]\n",
      " [ 204  216 1620]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      2062\n",
      "           1       0.88      0.86      0.87      2028\n",
      "           2       0.76      0.79      0.78      2040\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      6130\n",
      "   macro avg       0.84      0.84      0.84      6130\n",
      "weighted avg       0.84      0.84      0.84      6130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para un Dataset entrenamiento más pequeño**\n",
    "\n",
    "875*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S11   S12   S13   S14   S15    S16    S17   S18   S21   S22  ...   \\\n",
      "3042   5.0  -5.0  -4.0  -3.0  12.0    9.0   -4.0   2.0 -45.0  -9.0  ...    \n",
      "5537  52.0   4.0   1.0   6.0  -6.0  -10.0    7.0  29.0  -9.0   1.0  ...    \n",
      "506   38.0   0.0   7.0  16.0 -38.0   -6.0  127.0  40.0 -25.0  -2.0  ...    \n",
      "4969  25.0   3.0   4.0   5.0  -4.0   -6.0    2.0  10.0  -9.0  -2.0  ...    \n",
      "719    1.0  -3.0  -7.0  -6.0 -31.0   -7.0  -71.0 -43.0 -57.0  16.0  ...    \n",
      "8353  -7.0 -32.0  -7.0  -7.0  27.0    8.0    0.0   5.0   3.0  19.0  ...    \n",
      "1208  -7.0   4.0  -2.0  -9.0  -4.0  -17.0  -27.0   1.0 -12.0   3.0  ...    \n",
      "308    8.0   3.0   1.0   5.0   4.0   -8.0  -20.0  11.0 -52.0 -10.0  ...    \n",
      "6705   3.0 -14.0  -6.0  -5.0  15.0    9.0   -1.0 -18.0   1.0  15.0  ...    \n",
      "8488  -3.0  12.0  -6.0  -9.0 -12.0  -70.0  -17.0   4.0  20.0  20.0  ...    \n",
      "2623  -4.0  -2.0   0.0   6.0   8.0   10.0   25.0  21.0   2.0  -1.0  ...    \n",
      "6961 -12.0 -78.0  -5.0  -8.0  -9.0   -5.0   -2.0  -7.0  25.0  15.0  ...    \n",
      "3497 -57.0  -3.0  -3.0  -3.0  53.0   39.0    2.0 -21.0  68.0  16.0  ...    \n",
      "2937  -1.0   1.0  -3.0  -5.0  12.0   38.0   -2.0  -9.0   4.0   3.0  ...    \n",
      "2040   9.0 -15.0   0.0  14.0   6.0    7.0  -25.0 -13.0  -7.0 -14.0  ...    \n",
      "4612  51.0   4.0  -1.0  -2.0  11.0   21.0    1.0 -17.0  -4.0   0.0  ...    \n",
      "8534  16.0  -5.0  -5.0   1.0 -22.0  -51.0   -5.0  -3.0 -13.0  14.0  ...    \n",
      "5573 -32.0  -4.0   2.0  -1.0  32.0   16.0    0.0  -8.0 -11.0   1.0  ...    \n",
      "3775   1.0  -1.0   0.0   2.0  11.0   -1.0   -1.0   0.0  -1.0  -7.0  ...    \n",
      "3946 -13.0   1.0  -1.0   0.0  14.0   18.0    2.0  -7.0  25.0  -1.0  ...    \n",
      "7076   7.0  11.0  -3.0  -6.0  -3.0   15.0   19.0  -3.0  -3.0  -6.0  ...    \n",
      "8436   4.0 -17.0  -4.0  -7.0  -2.0   10.0   -3.0 -12.0 -10.0  -8.0  ...    \n",
      "2511  -2.0   0.0   1.0   8.0  -2.0   -6.0   -9.0   4.0 -26.0   3.0  ...    \n",
      "2814  -3.0  -2.0  -2.0  -1.0   6.0    6.0  -32.0 -13.0 -39.0   3.0  ...    \n",
      "7985  -1.0  -8.0   3.0  -3.0   7.0    9.0    3.0   0.0  -4.0  -4.0  ...    \n",
      "3447  13.0  -3.0  -1.0  -4.0   0.0   -5.0   -1.0  15.0  -8.0  -2.0  ...    \n",
      "7693   3.0  14.0  -1.0  -5.0   2.0   -6.0   -1.0  -7.0 -12.0 -35.0  ...    \n",
      "2983   1.0  -6.0  -3.0  -1.0   6.0   -5.0    4.0   8.0  -9.0   0.0  ...    \n",
      "1530  33.0  -4.0  -7.0   4.0 -13.0  -31.0 -128.0 -78.0  17.0   8.0  ...    \n",
      "966   -2.0  25.0   4.0   3.0  -4.0   15.0  127.0  31.0  28.0   6.0  ...    \n",
      "...    ...   ...   ...   ...   ...    ...    ...   ...   ...   ...  ...    \n",
      "5534 -17.0  -6.0  -2.0  -8.0 -23.0   -6.0   -5.0  -4.0  -6.0   2.0  ...    \n",
      "7570  13.0   2.0 -16.0  -5.0   5.0   -4.0    1.0   2.0   3.0  33.0  ...    \n",
      "1755  -6.0 -31.0 -21.0  -9.0   6.0  -18.0    3.0 -13.0  -2.0  -1.0  ...    \n",
      "5889 -22.0 -12.0  11.0  13.0  25.0  127.0   33.0  -8.0 -12.0  -3.0  ...    \n",
      "6972 -30.0 -13.0   2.0   7.0   9.0   39.0   -1.0   0.0  -9.0 -14.0  ...    \n",
      "3232  -3.0   0.0   0.0   4.0  17.0    8.0    2.0   3.0   1.0  -6.0  ...    \n",
      "2697  16.0  -6.0  -6.0  -5.0  -5.0    1.0  -32.0 -30.0  -8.0   0.0  ...    \n",
      "4658 -23.0  -3.0   1.0  -2.0 -17.0   15.0   -3.0  -8.0 -12.0  -2.0  ...    \n",
      "2157   0.0  10.0  17.0   3.0  13.0  -11.0    8.0   5.0   2.0   2.0  ...    \n",
      "7824  -8.0 -16.0  -3.0  -4.0  22.0   20.0    7.0  17.0 -13.0  -6.0  ...    \n",
      "5679  -8.0  -3.0  -1.0  -1.0  26.0    6.0    0.0  -8.0   3.0   1.0  ...    \n",
      "4400 -23.0  -4.0  -1.0   1.0   2.0   -4.0    2.0 -20.0   0.0   1.0  ...    \n",
      "5023 -10.0  -8.0  -5.0  -6.0 -16.0   37.0   -1.0  -5.0  -9.0   2.0  ...    \n",
      "6550 -49.0  12.0   7.0  11.0  14.0   18.0    8.0  -6.0 -11.0 -15.0  ...    \n",
      "6913  28.0 -15.0  -1.0  13.0  -5.0   24.0   -8.0   3.0  19.0   5.0  ...    \n",
      "7427 -37.0  13.0 -17.0 -10.0 -26.0  -13.0  -10.0 -12.0   8.0  13.0  ...    \n",
      "6785 -20.0  28.0   8.0  -4.0  22.0   -9.0   -2.0 -21.0  14.0  24.0  ...    \n",
      "8692   7.0  -4.0  -7.0  -7.0 -19.0  -25.0   -4.0  -8.0  -7.0 -15.0  ...    \n",
      "2975  -6.0  -3.0  -6.0  -7.0 -20.0   18.0    0.0  -4.0   1.0   2.0  ...    \n",
      "3325 -18.0  -2.0  -1.0   1.0  -9.0   13.0    0.0  -2.0  -8.0  -3.0  ...    \n",
      "1881  -8.0  -3.0  -1.0 -21.0  -3.0   -6.0  -23.0 -22.0  10.0  18.0  ...    \n",
      "7324   3.0  19.0   1.0   5.0  36.0   13.0    3.0  -9.0  -6.0 -13.0  ...    \n",
      "1160  19.0 -21.0  -5.0   3.0   1.0  -19.0  -19.0  -4.0 -43.0  13.0  ...    \n",
      "4861 -27.0  -3.0   1.0   4.0   4.0  -10.0    1.0   3.0   8.0   1.0  ...    \n",
      "7084 -15.0   3.0  -9.0  -5.0  -7.0   -4.0  -14.0 -11.0  13.0  -6.0  ...    \n",
      "1175  -4.0  -1.0  -6.0 -11.0 -15.0   -8.0   -8.0 -67.0  -8.0   4.0  ...    \n",
      "8447  -6.0  -8.0  -6.0  -6.0 -24.0   -6.0    4.0  20.0  -9.0  -9.0  ...    \n",
      "2934  12.0  -5.0   0.0   1.0  -5.0  -31.0   -4.0   6.0   7.0   3.0  ...    \n",
      "6618  15.0  18.0   2.0  -2.0   2.0   34.0    4.0 -15.0 -28.0 -35.0  ...    \n",
      "8510  32.0   9.0   1.0   1.0 -15.0   25.0    8.0  16.0   9.0 -11.0  ...    \n",
      "\n",
      "        S77   S78   S81   S82   S83   S84   S85   S86    S87   S88  \n",
      "3042    0.0  -8.0  -2.0   1.0   2.0   4.0 -23.0 -23.0    5.0   1.0  \n",
      "5537    4.0   9.0  -5.0  -1.0   0.0   0.0   2.0  -6.0   -1.0  -5.0  \n",
      "506   -93.0 -21.0 -10.0  -1.0  -1.0   0.0  -1.0   2.0   11.0 -39.0  \n",
      "4969    1.0   1.0  -2.0   0.0  -3.0  -3.0  13.0  14.0   -1.0  -4.0  \n",
      "719    74.0  41.0  18.0 -16.0   1.0 -29.0  14.0  23.0  -79.0 -11.0  \n",
      "8353   -6.0 -26.0  45.0   9.0  -6.0  -3.0  21.0  10.0    3.0   5.0  \n",
      "1208 -116.0 -11.0 -21.0   2.0  -4.0   7.0  24.0  54.0  118.0  26.0  \n",
      "308   -19.0 -21.0  53.0   4.0   1.0  -8.0  -9.0  -1.0   -1.0  -4.0  \n",
      "6705   -7.0  -9.0  -4.0   8.0   3.0  -1.0   1.0 -15.0    3.0   3.0  \n",
      "8488   -1.0 -10.0   7.0   1.0   3.0  17.0   7.0  -3.0   -1.0   2.0  \n",
      "2623  -19.0  -7.0  -1.0  -1.0   0.0   2.0 -11.0  -1.0   -4.0   0.0  \n",
      "6961  -12.0  25.0  24.0  12.0   0.0   1.0  -2.0  -7.0    5.0  -2.0  \n",
      "3497   -1.0   4.0 -10.0  -5.0  -5.0  -5.0  -8.0  12.0   -4.0  -8.0  \n",
      "2937    0.0 -10.0  12.0   6.0  -1.0   3.0  -8.0  -5.0    0.0   0.0  \n",
      "2040   52.0  16.0  26.0 -13.0  -8.0 -15.0   5.0  20.0  -28.0   0.0  \n",
      "4612    1.0   6.0   0.0   0.0  -1.0   1.0 -20.0 -21.0   -3.0  -6.0  \n",
      "8534   -5.0   6.0  -9.0  -1.0  -5.0  -1.0   8.0 -31.0    2.0   1.0  \n",
      "5573    1.0   0.0 -14.0  -6.0   2.0   7.0  -4.0   0.0    0.0  10.0  \n",
      "3775   -4.0   7.0 -10.0  -1.0  -1.0   2.0   0.0   5.0   -6.0  -7.0  \n",
      "3946    2.0   3.0   6.0   0.0   4.0   2.0  11.0  21.0   -2.0   1.0  \n",
      "7076   -8.0   8.0 -60.0   1.0  -3.0  -1.0  32.0  69.0    7.0   6.0  \n",
      "8436   -5.0   2.0   1.0  12.0   3.0  10.0 -17.0  -8.0   -1.0 -17.0  \n",
      "2511  -11.0  -9.0 -11.0  -3.0  -1.0   3.0  -2.0   3.0  -19.0   1.0  \n",
      "2814  -40.0 -47.0   6.0  -1.0   0.0   1.0  -3.0  11.0   75.0  36.0  \n",
      "7985   -4.0   9.0   5.0   5.0  -2.0   5.0   2.0   9.0    4.0   6.0  \n",
      "3447   -1.0  -2.0 -13.0   0.0   3.0   4.0 -62.0 -60.0   -4.0  -3.0  \n",
      "7693   -1.0  -5.0   4.0 -34.0  -8.0  -8.0   0.0 -22.0    2.0   2.0  \n",
      "2983    2.0 -18.0  -4.0   0.0   0.0  -1.0   3.0  -4.0    0.0   7.0  \n",
      "1530  -49.0   3.0  56.0   6.0  -3.0 -10.0   3.0  23.0   95.0   9.0  \n",
      "966    83.0  36.0 -17.0  -7.0 -19.0  -7.0   0.0  -4.0  -11.0 -19.0  \n",
      "...     ...   ...   ...   ...   ...   ...   ...   ...    ...   ...  \n",
      "5534   -1.0   0.0   6.0   2.0  -1.0   4.0  25.0  11.0    0.0  -6.0  \n",
      "7570    4.0 -14.0 -14.0   4.0  -7.0  -9.0 -31.0 -39.0   -6.0 -12.0  \n",
      "1755   -6.0 -11.0  10.0   3.0  -5.0 -18.0  -4.0  -9.0   -6.0   2.0  \n",
      "5889  -11.0 -24.0   1.0   0.0   4.0   2.0   7.0  -5.0    4.0  -5.0  \n",
      "6972  -24.0 -16.0 -26.0  -2.0 -10.0 -10.0   7.0   9.0    6.0  12.0  \n",
      "3232    0.0  -2.0   2.0  -1.0  -3.0  -7.0  -2.0  22.0    1.0  -1.0  \n",
      "2697   25.0 -57.0   9.0   1.0  -1.0  -2.0   8.0   5.0   20.0  34.0  \n",
      "4658   -4.0  -4.0   4.0   0.0  -5.0  -8.0  14.0  20.0   -1.0   2.0  \n",
      "2157   15.0  19.0   2.0 -10.0   1.0   0.0  -3.0   7.0   20.0  -3.0  \n",
      "7824  -11.0   1.0  -3.0  12.0   3.0   6.0   6.0  26.0    8.0  17.0  \n",
      "5679    1.0   5.0  -4.0  -3.0  -3.0  -6.0 -23.0   3.0   -3.0  -4.0  \n",
      "4400   -4.0  -9.0  -4.0  -3.0   1.0   0.0   0.0 -11.0   -4.0  -5.0  \n",
      "5023   -3.0  -9.0  -8.0  -2.0  -3.0  -6.0   7.0  14.0    2.0   0.0  \n",
      "6550  -11.0   5.0   6.0 -10.0  -5.0   1.0   7.0  56.0    8.0 -21.0  \n",
      "6913  -17.0  27.0  -9.0 -24.0  -7.0  -5.0  -2.0 -10.0    5.0 -19.0  \n",
      "7427   -4.0   1.0  -6.0  13.0   1.0   3.0  16.0   2.0    7.0   5.0  \n",
      "6785   17.0   6.0  12.0  -5.0  -8.0  -2.0   2.0 -28.0  -11.0 -12.0  \n",
      "8692   -3.0   6.0   2.0  37.0   4.0  -1.0  -7.0  33.0    2.0   9.0  \n",
      "2975   -4.0   5.0   7.0  -2.0   1.0  -1.0 -34.0 -33.0   -8.0  -6.0  \n",
      "3325   -2.0  -6.0   0.0   0.0  -1.0  -1.0  11.0  -5.0    1.0   0.0  \n",
      "1881    0.0 -15.0  -5.0 -12.0  -2.0  -3.0   2.0   4.0  -24.0   4.0  \n",
      "7324    3.0  16.0   6.0  12.0  11.0  22.0   8.0  -5.0    2.0  -4.0  \n",
      "1160  -68.0  -3.0  17.0 -21.0  -2.0   2.0  -9.0 -32.0 -104.0  -8.0  \n",
      "4861   -2.0  -1.0   4.0   1.0  -1.0  -4.0  16.0  10.0    1.0  -2.0  \n",
      "7084   -6.0   7.0 -34.0  -2.0   1.0   3.0   8.0  38.0   -9.0 -23.0  \n",
      "1175   27.0 -23.0 -96.0 -10.0  -5.0   1.0 -22.0 -42.0  -87.0 -41.0  \n",
      "8447   -2.0 -13.0  21.0  40.0  12.0  -3.0 -10.0 -41.0  -11.0   1.0  \n",
      "2934    1.0   4.0  -8.0   2.0  -2.0  -3.0  12.0  17.0    0.0   2.0  \n",
      "6618    1.0   7.0 -29.0 -19.0  -4.0  -7.0 -16.0 -41.0   -9.0 -32.0  \n",
      "8510   -6.0   1.0   2.0   7.0  -5.0  -8.0  -7.0  22.0    0.0 -12.0  \n",
      "\n",
      "[875 rows x 64 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.1, random_state=25)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2135   54  435]\n",
      " [  49 2262  287]\n",
      " [ 443  275 1941]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      2624\n",
      "           1       0.87      0.87      0.87      2598\n",
      "           2       0.73      0.73      0.73      2659\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      7881\n",
      "   macro avg       0.80      0.80      0.80      7881\n",
      "weighted avg       0.80      0.80      0.80      7881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset entrenamiento aún más pequeño**\n",
    "\n",
    "87*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S11   S12   S13   S14   S15    S16    S17   S18   S21   S22  ...   \\\n",
      "7500   2.0 -15.0  -8.0  -6.0 -21.0  -17.0   -3.0   5.0  12.0  -1.0  ...    \n",
      "5712  -5.0  -5.0   0.0  -7.0 -73.0  -34.0   -3.0 -13.0 -19.0   8.0  ...    \n",
      "1251  18.0  -9.0  -2.0  15.0   5.0   17.0 -116.0  -6.0 -24.0  -3.0  ...    \n",
      "4368 -14.0  -1.0   0.0   2.0 -39.0   -5.0   -2.0  -2.0  47.0   3.0  ...    \n",
      "8576   8.0   7.0   2.0   1.0  24.0   16.0    1.0  13.0  -6.0  10.0  ...    \n",
      "840   60.0  12.0 -10.0 -36.0  -3.0    6.0   14.0   2.0   1.0 -13.0  ...    \n",
      "1859  -3.0   7.0  -6.0  -8.0  -3.0  -11.0    3.0 -10.0  -5.0   3.0  ...    \n",
      "2103 -22.0   6.0   1.0   6.0  16.0   20.0   36.0   4.0  12.0 -17.0  ...    \n",
      "6433 -24.0   0.0  -4.0   5.0  -1.0    6.0   -8.0 -23.0  -3.0  22.0  ...    \n",
      "1454  -3.0   0.0  -2.0  -3.0   2.0  -10.0  -39.0 -58.0   4.0   1.0  ...    \n",
      "6483 -20.0 -13.0  -1.0  -5.0   0.0   -4.0   -7.0   8.0 -16.0  -2.0  ...    \n",
      "583   36.0  -1.0  -1.0   4.0  -9.0   10.0   11.0   7.0 -12.0  -2.0  ...    \n",
      "8076  -6.0  -4.0  -2.0  -8.0  14.0   19.0    2.0  -5.0   5.0  10.0  ...    \n",
      "5503  37.0   2.0   2.0   1.0 -30.0  -10.0    0.0   8.0 -26.0  -3.0  ...    \n",
      "7197  -1.0  -6.0   0.0   5.0   2.0   -2.0   -9.0  13.0  10.0  10.0  ...    \n",
      "1553  -1.0  -4.0  -7.0 -14.0  17.0   10.0  -60.0  37.0 -22.0   0.0  ...    \n",
      "2743  -7.0   1.0   1.0   6.0  -6.0   -2.0   -3.0  -6.0  -4.0  -3.0  ...    \n",
      "4034 -24.0  -1.0  -3.0  -2.0   8.0   25.0   -4.0 -14.0  15.0   9.0  ...    \n",
      "3749 -14.0  -4.0  -1.0   3.0  11.0   15.0    0.0  -4.0  -6.0   0.0  ...    \n",
      "5259   8.0   2.0  -2.0  -4.0 -23.0   15.0    1.0   0.0  -3.0   1.0  ...    \n",
      "147  -18.0   2.0   4.0  12.0   9.0   -3.0    1.0  11.0  53.0  -1.0  ...    \n",
      "5742 -18.0   0.0   3.0   2.0   8.0  -23.0   -2.0  -7.0 -34.0  -4.0  ...    \n",
      "3795  -6.0   2.0   2.0   6.0   9.0  -26.0   -4.0  -5.0  12.0   4.0  ...    \n",
      "4613  -2.0  -2.0  -2.0  -2.0 -17.0   -4.0   -4.0  -1.0 -20.0  -2.0  ...    \n",
      "3935  48.0  -6.0  -1.0  -2.0  15.0  -11.0   -6.0 -14.0 -19.0  -3.0  ...    \n",
      "160  -41.0  -3.0  -1.0 -13.0  -4.0   -6.0    2.0 -22.0  26.0  -6.0  ...    \n",
      "2499  10.0  -6.0  -1.0   4.0   6.0   14.0   27.0 -20.0 -17.0  -8.0  ...    \n",
      "251  -21.0  -2.0  -4.0  -9.0  -7.0   -2.0   36.0  -3.0  12.0   2.0  ...    \n",
      "7576 -14.0 -64.0 -20.0 -10.0  -1.0    0.0   -1.0  -8.0  45.0  23.0  ...    \n",
      "2477   2.0  -2.0  -2.0  -9.0   3.0    1.0    4.0  -4.0 -52.0   6.0  ...    \n",
      "...    ...   ...   ...   ...   ...    ...    ...   ...   ...   ...  ...    \n",
      "5534 -17.0  -6.0  -2.0  -8.0 -23.0   -6.0   -5.0  -4.0  -6.0   2.0  ...    \n",
      "7570  13.0   2.0 -16.0  -5.0   5.0   -4.0    1.0   2.0   3.0  33.0  ...    \n",
      "1755  -6.0 -31.0 -21.0  -9.0   6.0  -18.0    3.0 -13.0  -2.0  -1.0  ...    \n",
      "5889 -22.0 -12.0  11.0  13.0  25.0  127.0   33.0  -8.0 -12.0  -3.0  ...    \n",
      "6972 -30.0 -13.0   2.0   7.0   9.0   39.0   -1.0   0.0  -9.0 -14.0  ...    \n",
      "3232  -3.0   0.0   0.0   4.0  17.0    8.0    2.0   3.0   1.0  -6.0  ...    \n",
      "2697  16.0  -6.0  -6.0  -5.0  -5.0    1.0  -32.0 -30.0  -8.0   0.0  ...    \n",
      "4658 -23.0  -3.0   1.0  -2.0 -17.0   15.0   -3.0  -8.0 -12.0  -2.0  ...    \n",
      "2157   0.0  10.0  17.0   3.0  13.0  -11.0    8.0   5.0   2.0   2.0  ...    \n",
      "7824  -8.0 -16.0  -3.0  -4.0  22.0   20.0    7.0  17.0 -13.0  -6.0  ...    \n",
      "5679  -8.0  -3.0  -1.0  -1.0  26.0    6.0    0.0  -8.0   3.0   1.0  ...    \n",
      "4400 -23.0  -4.0  -1.0   1.0   2.0   -4.0    2.0 -20.0   0.0   1.0  ...    \n",
      "5023 -10.0  -8.0  -5.0  -6.0 -16.0   37.0   -1.0  -5.0  -9.0   2.0  ...    \n",
      "6550 -49.0  12.0   7.0  11.0  14.0   18.0    8.0  -6.0 -11.0 -15.0  ...    \n",
      "6913  28.0 -15.0  -1.0  13.0  -5.0   24.0   -8.0   3.0  19.0   5.0  ...    \n",
      "7427 -37.0  13.0 -17.0 -10.0 -26.0  -13.0  -10.0 -12.0   8.0  13.0  ...    \n",
      "6785 -20.0  28.0   8.0  -4.0  22.0   -9.0   -2.0 -21.0  14.0  24.0  ...    \n",
      "8692   7.0  -4.0  -7.0  -7.0 -19.0  -25.0   -4.0  -8.0  -7.0 -15.0  ...    \n",
      "2975  -6.0  -3.0  -6.0  -7.0 -20.0   18.0    0.0  -4.0   1.0   2.0  ...    \n",
      "3325 -18.0  -2.0  -1.0   1.0  -9.0   13.0    0.0  -2.0  -8.0  -3.0  ...    \n",
      "1881  -8.0  -3.0  -1.0 -21.0  -3.0   -6.0  -23.0 -22.0  10.0  18.0  ...    \n",
      "7324   3.0  19.0   1.0   5.0  36.0   13.0    3.0  -9.0  -6.0 -13.0  ...    \n",
      "1160  19.0 -21.0  -5.0   3.0   1.0  -19.0  -19.0  -4.0 -43.0  13.0  ...    \n",
      "4861 -27.0  -3.0   1.0   4.0   4.0  -10.0    1.0   3.0   8.0   1.0  ...    \n",
      "7084 -15.0   3.0  -9.0  -5.0  -7.0   -4.0  -14.0 -11.0  13.0  -6.0  ...    \n",
      "1175  -4.0  -1.0  -6.0 -11.0 -15.0   -8.0   -8.0 -67.0  -8.0   4.0  ...    \n",
      "8447  -6.0  -8.0  -6.0  -6.0 -24.0   -6.0    4.0  20.0  -9.0  -9.0  ...    \n",
      "2934  12.0  -5.0   0.0   1.0  -5.0  -31.0   -4.0   6.0   7.0   3.0  ...    \n",
      "6618  15.0  18.0   2.0  -2.0   2.0   34.0    4.0 -15.0 -28.0 -35.0  ...    \n",
      "8510  32.0   9.0   1.0   1.0 -15.0   25.0    8.0  16.0   9.0 -11.0  ...    \n",
      "\n",
      "       S77   S78   S81   S82   S83   S84   S85   S86    S87   S88  \n",
      "7500   4.0  -3.0  -7.0 -18.0  -7.0  -5.0  18.0 -17.0   -4.0 -12.0  \n",
      "5712  -1.0  -4.0  12.0   3.0   2.0   5.0   7.0   1.0    3.0   4.0  \n",
      "1251  -7.0   1.0  -7.0  23.0   7.0   0.0  -5.0  35.0  -24.0  -6.0  \n",
      "4368   3.0  16.0   8.0   4.0   4.0   7.0  35.0  -8.0    2.0   5.0  \n",
      "8576  -4.0   4.0   0.0   0.0  -1.0   0.0  -1.0  -3.0   -1.0  -1.0  \n",
      "840   13.0 -12.0  -5.0  -3.0  -3.0   0.0   7.0  27.0  -47.0  -5.0  \n",
      "1859  10.0 -43.0  -7.0  16.0  -8.0 -20.0   7.0  -3.0   -3.0  26.0  \n",
      "2103  22.0   3.0 -45.0 -20.0   1.0   1.0  14.0  -8.0  -21.0   2.0  \n",
      "6433   4.0   0.0 -23.0 -18.0  -8.0  -4.0  13.0 -21.0   -1.0 -12.0  \n",
      "1454  82.0  36.0  16.0   5.0   9.0  11.0   8.0  11.0   34.0   5.0  \n",
      "6483   4.0  -4.0  -2.0  -2.0  -3.0  -1.0 -23.0 -20.0    4.0   0.0  \n",
      "583   27.0  -3.0 -11.0   0.0   0.0  10.0  -1.0   6.0   -1.0  11.0  \n",
      "8076   0.0  36.0 -61.0 -12.0   0.0  -2.0   1.0   2.0    0.0  -1.0  \n",
      "5503  -4.0 -14.0   1.0   2.0   0.0  -1.0  -6.0 -11.0    3.0   0.0  \n",
      "7197   4.0   5.0 -27.0 -14.0   0.0   3.0 -24.0 -38.0   -6.0  -9.0  \n",
      "1553 -32.0  -5.0  -3.0  -2.0   2.0  -4.0  24.0  -1.0   11.0  15.0  \n",
      "2743 -45.0   4.0   9.0   3.0   4.0   3.0  -1.0 -10.0   14.0  -1.0  \n",
      "4034  -5.0 -12.0   6.0  -3.0   1.0   2.0  -3.0  24.0    2.0   5.0  \n",
      "3749   3.0   9.0  14.0   5.0  -2.0   2.0  -8.0   8.0    2.0  -4.0  \n",
      "5259  -4.0  -3.0 -17.0   2.0   3.0   4.0   3.0   7.0    1.0   3.0  \n",
      "147  -42.0  -6.0 -11.0   1.0   3.0   0.0   6.0  -3.0   -5.0   2.0  \n",
      "5742  -7.0 -18.0  11.0   4.0   1.0   2.0  25.0  18.0    6.0  26.0  \n",
      "3795  -5.0  -1.0  -4.0  -2.0   1.0   2.0   0.0  -4.0    2.0   2.0  \n",
      "4613   5.0   3.0  13.0   1.0  -3.0   1.0 -13.0   4.0   -3.0 -24.0  \n",
      "3935  -2.0  -5.0   7.0  -6.0  -3.0  -5.0  -1.0  27.0    0.0   9.0  \n",
      "160  -17.0   7.0  -6.0  -1.0  -1.0   0.0 -12.0 -10.0    2.0  13.0  \n",
      "2499  -3.0  17.0   1.0   0.0  -3.0  10.0   0.0  -8.0  -65.0 -23.0  \n",
      "251   -2.0   7.0 -17.0  -3.0   2.0   0.0   3.0  -1.0  -30.0  19.0  \n",
      "7576   0.0  -3.0  13.0  24.0  -3.0   1.0   9.0  -4.0   -9.0   6.0  \n",
      "2477 -46.0  -6.0   1.0  -1.0  -1.0   3.0  -4.0 -15.0   44.0   7.0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...    ...   ...  \n",
      "5534  -1.0   0.0   6.0   2.0  -1.0   4.0  25.0  11.0    0.0  -6.0  \n",
      "7570   4.0 -14.0 -14.0   4.0  -7.0  -9.0 -31.0 -39.0   -6.0 -12.0  \n",
      "1755  -6.0 -11.0  10.0   3.0  -5.0 -18.0  -4.0  -9.0   -6.0   2.0  \n",
      "5889 -11.0 -24.0   1.0   0.0   4.0   2.0   7.0  -5.0    4.0  -5.0  \n",
      "6972 -24.0 -16.0 -26.0  -2.0 -10.0 -10.0   7.0   9.0    6.0  12.0  \n",
      "3232   0.0  -2.0   2.0  -1.0  -3.0  -7.0  -2.0  22.0    1.0  -1.0  \n",
      "2697  25.0 -57.0   9.0   1.0  -1.0  -2.0   8.0   5.0   20.0  34.0  \n",
      "4658  -4.0  -4.0   4.0   0.0  -5.0  -8.0  14.0  20.0   -1.0   2.0  \n",
      "2157  15.0  19.0   2.0 -10.0   1.0   0.0  -3.0   7.0   20.0  -3.0  \n",
      "7824 -11.0   1.0  -3.0  12.0   3.0   6.0   6.0  26.0    8.0  17.0  \n",
      "5679   1.0   5.0  -4.0  -3.0  -3.0  -6.0 -23.0   3.0   -3.0  -4.0  \n",
      "4400  -4.0  -9.0  -4.0  -3.0   1.0   0.0   0.0 -11.0   -4.0  -5.0  \n",
      "5023  -3.0  -9.0  -8.0  -2.0  -3.0  -6.0   7.0  14.0    2.0   0.0  \n",
      "6550 -11.0   5.0   6.0 -10.0  -5.0   1.0   7.0  56.0    8.0 -21.0  \n",
      "6913 -17.0  27.0  -9.0 -24.0  -7.0  -5.0  -2.0 -10.0    5.0 -19.0  \n",
      "7427  -4.0   1.0  -6.0  13.0   1.0   3.0  16.0   2.0    7.0   5.0  \n",
      "6785  17.0   6.0  12.0  -5.0  -8.0  -2.0   2.0 -28.0  -11.0 -12.0  \n",
      "8692  -3.0   6.0   2.0  37.0   4.0  -1.0  -7.0  33.0    2.0   9.0  \n",
      "2975  -4.0   5.0   7.0  -2.0   1.0  -1.0 -34.0 -33.0   -8.0  -6.0  \n",
      "3325  -2.0  -6.0   0.0   0.0  -1.0  -1.0  11.0  -5.0    1.0   0.0  \n",
      "1881   0.0 -15.0  -5.0 -12.0  -2.0  -3.0   2.0   4.0  -24.0   4.0  \n",
      "7324   3.0  16.0   6.0  12.0  11.0  22.0   8.0  -5.0    2.0  -4.0  \n",
      "1160 -68.0  -3.0  17.0 -21.0  -2.0   2.0  -9.0 -32.0 -104.0  -8.0  \n",
      "4861  -2.0  -1.0   4.0   1.0  -1.0  -4.0  16.0  10.0    1.0  -2.0  \n",
      "7084  -6.0   7.0 -34.0  -2.0   1.0   3.0   8.0  38.0   -9.0 -23.0  \n",
      "1175  27.0 -23.0 -96.0 -10.0  -5.0   1.0 -22.0 -42.0  -87.0 -41.0  \n",
      "8447  -2.0 -13.0  21.0  40.0  12.0  -3.0 -10.0 -41.0  -11.0   1.0  \n",
      "2934   1.0   4.0  -8.0   2.0  -2.0  -3.0  12.0  17.0    0.0   2.0  \n",
      "6618   1.0   7.0 -29.0 -19.0  -4.0  -7.0 -16.0 -41.0   -9.0 -32.0  \n",
      "8510  -6.0   1.0   2.0   7.0  -5.0  -8.0  -7.0  22.0    0.0 -12.0  \n",
      "\n",
      "[87 rows x 64 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.01, random_state=25)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2302  103  474]\n",
      " [ 133 2204  539]\n",
      " [ 770  491 1653]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76      2879\n",
      "           1       0.79      0.77      0.78      2876\n",
      "           2       0.62      0.57      0.59      2914\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      8669\n",
      "   macro avg       0.71      0.71      0.71      8669\n",
      "weighted avg       0.71      0.71      0.71      8669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras más pequeño es el dataset de entrenamiento, menor es la precision y recall, debido a que no representan un conjunto significativo de datos para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pricila\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:2366: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6), tight_layout=True, sharex=True, sharey=True)\n",
    "x = np.arange(8756*64)\n",
    "y = np.arange(0,1)\n",
    "\n",
    "plt.xlabel('Tamaño Dataset Entrenamiento', size=20)\n",
    "plt.ylabel('Precision',size=20)\n",
    "\n",
    "plt.title('Tamaño vs Precision')\n",
    "\n",
    "plt.plot([2626*64,875*64,87*64],[0.95, 0.89, 0.72],'ro',color=\"RED\")\n",
    "plt.plot([2626*64,875*64,87*64],[0.97, 0.87, 0.79],'ro',color=\"BLUE\")\n",
    "plt.plot([2626*64,875*64,87*64],[0.93, 0.73, 0.62],'ro',color=\"GREEN\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Rojo es el caso de 0\n",
    "    Azul es el caso de 1\n",
    "    Verde es el caso de 2\n",
    "    \n",
    "En los tres casos de ve que a medida que aumenta la dataset de entrenamiento (eje x) la precision aumenta (eje y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
